{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38e1b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Progress list ###\n",
    "\"\"\"\n",
    "DONE:\n",
    "- Check and remove overlapping spwr events\n",
    "- Create spwr dataset with 100ms around each spwr peak\n",
    "    - Plot the events\n",
    "    - Plot the entire signal but with spwr marked in red\n",
    "- Create noise dataset. Ensure it does not contain any spwr events. Maybe plot to make sure in case Peter missed spwr events.\n",
    "- Train test split\n",
    "- Train the model\n",
    "- Label parts of the code and give instructions at code segments where a lot of manual work is done.\n",
    "\n",
    "WORK IN PROGRESS:            \n",
    "\n",
    "\n",
    "TODO:\n",
    "- Fix a way to not have Keras overwrite models\n",
    "- Create a function for plotting just to clean up the code further\n",
    "\n",
    "#UGLY CODE PARTS:\n",
    " - Everything with np.delete because it creates a copy of the array which takes up a lot of memory and unnecessary time\n",
    " - That I have to go through the noise range and manually select ranges that could contain non noise\n",
    " - That I after creating the noise data set loop through it again and manually mark ranges that are possible spwrs\n",
    "   and then manually find noise data to replace it which is done now by finding a sequential range of data that is\n",
    "   maybe_non_noise_indicies.shape[0]*201 long without any possible spwr inside of it. I do this now by adding a number\n",
    "   to the last frame from which the noise dataset was created. But this is not a good strategy if a lot of data is needed.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f48d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "import h5py\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "#Needed for Keras\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe3c13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"Num CPUs Available: \", len(tf.config.list_physical_devices('CPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8bb3c8",
   "metadata": {},
   "source": [
    "## Load data from MATLAB ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0df9f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOAD DATA ###\n",
    "\n",
    "# Current path\n",
    "cwd = os.getcwd()\n",
    "\n",
    "work_dir = r\"C:\\Users\\RIPPLE\\source\\repos\\spwr-project\"\n",
    "data_dir = r\"D:\\Dropbox (Personal)\\ETH_DATA\\rTBY35\\8_freely_behav_220517_120301\"\n",
    "# D:\\Dropbox (Personal)\\ETH_DATA\\rTBY35\\7_freely_behav_220511_152446\n",
    "os.chdir(data_dir)\n",
    "\n",
    "# Load data for determining the type of spwr event\n",
    "g = scipy.io.loadmat('spwr_indicies.mat')\n",
    "high_dHP_bool = (g['bzHigh_dHP_ind'].flatten()).astype(bool)\n",
    "low_dHP_bool = (g['bzLow_dHP_ind'].flatten()).astype(bool)\n",
    "high_iHP_bool = (g['bzHigh_iHP_ind'].flatten()).astype(bool)\n",
    "low_iHP_bool = (g['bzLow_iHP_ind'].flatten()).astype(bool)\n",
    "\n",
    "# Load lfp and ripple data\n",
    "f = h5py.File('8_freely_behav_220517_120301_auto_features.mat','r')\n",
    "lfp_channels = np.array(f.get('lfp/data')) # (16, 7403751)\n",
    "#lfp_lowpass = np.array(f.get('lfp/lowpass'))\n",
    "#lfp_lowpass_all = np.array(f.get('lfp/lowpass_all'))\n",
    "#lfp_bandpass = np.array(f.get('lfp/bandpass'))\n",
    "#lfp_bandpass_power = np.array(f.get('lfp/bandpass_power'))\n",
    "ripple_timestamps = np.array(f.get('ripples/timestamps')) #(2, 1467)\n",
    "ripple_durations = np.array(f.get('ripples/duration')) #(1, 1467)\n",
    "ripple_centralFrames = np.array(f.get('rippleEpisodes/centralFrames')).astype(int).transpose() #(1, 1467)\n",
    "lfp_main_channels_dHP = np.array(f.get('lfp_main_channel_dHP')).flatten().astype(int)-1 #-1 for python zero-indexing\n",
    "lfp_main_channels_iHP = np.array(f.get('lfp_main_channel_iHP')).flatten().astype(int)-1 #-1 for python zero-indexing\n",
    "\n",
    "os.chdir(work_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d359e422",
   "metadata": {},
   "source": [
    "## Collect spwr data for all ripples and only dHP ripples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db003d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timestamps for dHP spwr events, both high and low\n",
    "dHP_spwr_bool = np.logical_or(high_dHP_bool, low_dHP_bool)\n",
    "\n",
    "dHP_spwr_timestamps = ripple_timestamps[:, dHP_spwr_bool] #(2, 878)\n",
    "dHP_spwr_durations = ripple_durations[:, dHP_spwr_bool] #(1, 878)\n",
    "dHP_spwr_centralFrames = ripple_centralFrames[:, dHP_spwr_bool] #(1, 878)\n",
    "\n",
    "# Timestamps for iHP spwr events\n",
    "#iHP_spwr_bool = np.logical_or(high_iHP_bool, low_iHP_bool)\n",
    "#iHP_spwr_timestamps = ripple_timestamps[:, iHP_spwr_bool] # (2, 589)\n",
    "\n",
    "# Timestamps for separate spwr events\n",
    "#high_dHP_spwr_timestamps = ripple_timestamps[:, high_dHP_bool] #(2, 589)\n",
    "#low_dHP_spwr_timestamps = ripple_timestamps[:, low_dHP_bool] #(2, 289)\n",
    "#high_iHP_spwr_timestamps = ripple_timestamps[:, high_iHP_bool] #(2, 384)\n",
    "#low_iHP_spwr_timestamps = ripple_timestamps[:, low_iHP_bool] #(2, 205)\n",
    "\n",
    "# All spwr timestamps sorted by start time\n",
    "# Needed for calculating overlapping spwr events\n",
    "sorted_ripple_timestamps_ind = np.argsort(ripple_timestamps[0, :])\n",
    "sorted_ripple_timestamps = ripple_timestamps[:, sorted_ripple_timestamps_ind]\n",
    "sorted_ripple_centralFrames = ripple_centralFrames[:, sorted_ripple_timestamps_ind] #(1, 1467)\n",
    "\n",
    "#Sort the dHP spwr timestamps according to start time\n",
    "sort_indicies = np.argsort(dHP_spwr_timestamps[0, :])\n",
    "dHP_spwr_timestamps = dHP_spwr_timestamps[:, sort_indicies] #(2, 878)\n",
    "dHP_spwr_durations = dHP_spwr_durations[:, sort_indicies] #(1, 878)\n",
    "dHP_spwr_centralFrames = dHP_spwr_centralFrames[:, sort_indicies] #(1, 878)\n",
    "\n",
    "num_dHP_spwr = np.sum(dHP_spwr_bool) #878\n",
    "num_total_spwr = ripple_timestamps.shape[1] #1467\n",
    "\n",
    "#Only use most informative channels (picked by Peter)\n",
    "lfp_dHP_data = lfp_channels[lfp_main_channels_dHP, :] #3, 7403751\n",
    "num_channels = len(lfp_main_channels_dHP)\n",
    "\n",
    "\n",
    "max_ripple_duration = np.max(ripple_durations) #0.09850000000005821 seconds => 100ms around each spwr to not miss any data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9ebf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution of ripple durations\n",
    "counts, bins = np.histogram(ripple_durations)\n",
    "plt.stairs(counts, bins)\n",
    "plt.show()\n",
    "#print(np.sort(ripple_durations)[:, -100:])\n",
    "# Only a small fraction are very long spwr events. But I cannot discard them just like that because \n",
    "# I want the algorithm to also learn this general behaviour of spwr events and therefore longer spwr events are needed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b7f1f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f658377c",
   "metadata": {},
   "source": [
    "### Only use non-overlapping dHP spwr ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d871e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code extracts spwrs' centralFrame if the spwr does not overlap other spwrs, \n",
    "#i.e. within 100ms of each other from the center.\n",
    "#This is done to have isolated spwrs in the training/test set and to avoid the same data in different samples.\n",
    "#Hopefully this allows the model to better learn what a spwr is.\n",
    "\n",
    "#The end result is that we are provided with the sorted dHP spwrs\n",
    "\n",
    "timesteps = 100\n",
    "spwr_size = 2*timesteps+1\n",
    "\n",
    "#Copy of all spwr centralFrames. Overlapping spwr frames are removed.\n",
    "copy_centralFrames = np.copy(sorted_ripple_centralFrames)\n",
    "copy_centralFrames = copy_centralFrames.flatten() #Flatten => (num_spwr, )\n",
    " \n",
    "#Current index in array with removed overlapping spwrs\n",
    "idx = 0\n",
    "\n",
    "#Index of current and next spwr of all spwr events\n",
    "curr_spwr = 0\n",
    "next_spwr = 1\n",
    "\n",
    "#spwr events to be removed because of overlapping iHP and dHP as iHP spwr is still captured by dHP channels\n",
    "non_overlapping_spwr = []\n",
    "\n",
    "num_dHP_removed = 0\n",
    "num_iHP_removed = 0\n",
    "\n",
    "#Initiate previously removed ripple end frame to start of time series, i.e. 0\n",
    "prev_ripple_end = 0\n",
    "\n",
    "#While there are at least 2 non-overlapping or potentially non-overlapping spwr events left. \n",
    "#If only one left I cannot compare it to anything\n",
    "num_spwr_left = copy_centralFrames.shape[0] - 1 \n",
    "while idx < num_spwr_left:\n",
    "    \n",
    "    curr_ripple_start = copy_centralFrames[idx] - timesteps\n",
    "    curr_ripple_end = copy_centralFrames[idx] + timesteps\n",
    "    next_ripple_start = copy_centralFrames[idx+1] - timesteps\n",
    "    next_ripple_end = copy_centralFrames[idx+1] + timesteps\n",
    "    \n",
    "    #Remove curr ripple if curr ripple overlaps with previously removed ripple\n",
    "    if(curr_ripple_start <= prev_ripple_end):\n",
    "        copy_centralFrames = np.delete(copy_centralFrames, idx)\n",
    "        \n",
    "        if(dHP_spwr_bool[curr_spwr]):\n",
    "            num_dHP_removed += 1\n",
    "        \n",
    "        else:\n",
    "            num_iHP_removed += 1\n",
    "            \n",
    "        prev_ripple_end = curr_ripple_end\n",
    "        num_spwr_left += -1\n",
    "        curr_spwr += 1\n",
    "        next_spwr += 1\n",
    "        \n",
    "    #Remove curr and next ripple if next ripple overlaps with current ripple \n",
    "    elif(curr_ripple_start <= next_ripple_start <= curr_ripple_end):\n",
    "        \n",
    "        #Discard both overlapping spwr events one after another\n",
    "        copy_centralFrames = np.delete(copy_centralFrames, idx) #This discard curr\n",
    "        copy_centralFrames = np.delete(copy_centralFrames, idx) #This discards next which is now at curr pos\n",
    "\n",
    "        if(dHP_spwr_bool[curr_spwr]):\n",
    "            num_dHP_removed += 1\n",
    "        \n",
    "        else:\n",
    "            num_iHP_removed += 1\n",
    "        \n",
    "        if(dHP_spwr_bool[curr_spwr+1]):\n",
    "            num_dHP_removed += 1\n",
    "        else:\n",
    "            num_iHP_removed += 1\n",
    "        \n",
    "        prev_ripple_end = next_ripple_end\n",
    "        num_spwr_left += -2  \n",
    "        curr_spwr += 2\n",
    "        next_spwr += 2\n",
    "    \n",
    "    #No overlap => save current spwr as non-overlapping and go to next spwr\n",
    "    else:\n",
    "        prev_ripple_end = curr_ripple_end\n",
    "        non_overlapping_spwr.append(curr_spwr)\n",
    "        curr_spwr = next_spwr\n",
    "        idx+= 1\n",
    "        next_spwr += 1 \n",
    "\n",
    "#If last ripple does not overlap with previous ripple we add it\n",
    "curr_ripple_start = copy_centralFrames[idx] - timesteps\n",
    "if(curr_ripple_start > prev_ripple_end):\n",
    "    non_overlapping_spwr.append(curr_spwr)\n",
    "\n",
    "print(\"Total number of spwr: \", num_total_spwr)\n",
    "print(\"Total number of dHP spwr\", num_dHP_spwr)\n",
    "print(\"Total number of removed overlapping spwr events: \", len(non_overlapping_spwr)) \n",
    "print(\"Number of dHP spwr removed: \", num_dHP_removed)\n",
    "print(\"Number of iHP spwr removed: \", num_iHP_removed)\n",
    "print(\"Portion of total lost spwr events: \", len(non_overlapping_spwr)/num_total_spwr)\n",
    "print(\"Portion of total lost dHP spwr events: \", num_dHP_removed/num_dHP_spwr)\n",
    "\n",
    "#True if spwr event is not removed\n",
    "#False is spwr event is removed\n",
    "kept_spwr_bool = np.full((num_total_spwr), False) # Creates boolean array with all False values\n",
    "for spwr_idx in non_overlapping_spwr:\n",
    "    kept_spwr_bool[spwr_idx] = True\n",
    "    \n",
    "#Only non-removed dHP spwr events are kept\n",
    "non_overlapping_dHP_spwr_bool = np.logical_and(kept_spwr_bool, dHP_spwr_bool)\n",
    "print(\"Shape of non_overlapping_dHP_spwr_bool: \", non_overlapping_dHP_spwr_bool.shape)\n",
    "print(\"Num non-overlapping dHP spwrs: \", np.sum(non_overlapping_dHP_spwr_bool))\n",
    "\n",
    "num_non_overlapping_dHP_spwr = np.sum(non_overlapping_dHP_spwr_bool)\n",
    "\n",
    "##Get lfp data only for non-overlapping dHP spwr events\n",
    "#Sorted array with the centralFrames of non-overlapping dHP spwrs\n",
    "dHP_non_overlapping_centralFrames = sorted_ripple_centralFrames[0, non_overlapping_dHP_spwr_bool]\n",
    "\n",
    "#Create structure for storing the lfp data corresponding to each non-overlapping dHP spwr and load in the data\n",
    "#Channel, spwr id, lfp data\n",
    "non_overlapping_lfp_dHP_spwr = np.zeros((num_channels, num_non_overlapping_dHP_spwr, spwr_size)) \n",
    "\n",
    "for j, spwr_centralFrame in enumerate(dHP_non_overlapping_centralFrames):\n",
    "    start = spwr_centralFrame - 100\n",
    "    end = spwr_centralFrame + 101\n",
    "    non_overlapping_lfp_dHP_spwr[:, j, :] = lfp_dHP_data[:, start:end]\n",
    "\n",
    "print(\"Number of high dHP spwrs in non overlapping: \", np.sum(np.logical_and(high_dHP_bool, non_overlapping_dHP_spwr_bool)))\n",
    "print(\"Number of high dHP spwrs in non overlapping: \", np.sum(np.logical_and(low_dHP_bool, non_overlapping_dHP_spwr_bool)))\n",
    "\n",
    "non_overlapping_dHP_ripple_durations = ripple_durations[:, non_overlapping_dHP_spwr_bool]\n",
    "\n",
    "#Distribution of ripple durations\n",
    "counts, bins = np.histogram(non_overlapping_dHP_ripple_durations)\n",
    "plt.stairs(counts, bins)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4e76c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60c5ba45",
   "metadata": {},
   "source": [
    "### PLOTTING ###\n",
    "This section does not have to be run to get the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a989c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8cc4fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3893bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract frames that are not labelled as spwr (100 frames left and right around each spwr centralFrame i.e 100ms)\n",
    "\n",
    "start_frames = sorted_ripple_centralFrames[0, :] - 100\n",
    "end_frames = sorted_ripple_centralFrames[0, :] + 101 #101 because python does not include last idx in range\n",
    "\n",
    "# TODO, make this more efficient instead of np.delete which creates a new array every time\n",
    "non_spwr_frames = np.arange(0, 7403751)\n",
    "for i in range(len(sorted_ripple_centralFrames[0, :])):\n",
    "    start_frame = start_frames[i]\n",
    "    end_frame = end_frames[i]\n",
    "    non_spwr_frames = np.delete(non_spwr_frames, np.argwhere((non_spwr_frames >= start_frame) & (non_spwr_frames <= end_frame)))\n",
    "\n",
    "print(\"Number of timepoints: \", lfp_dHP_data.shape[1])\n",
    "# Plot all of the data\n",
    "plt.figure()\n",
    "str_idx = 0\n",
    "end_idx = lfp_dHP_data.shape[1]\n",
    "plt.plot(np.arange(len(lfp_dHP_data[0, str_idx:end_idx])),lfp_dHP_data[0, str_idx:end_idx], alpha=0.8)\n",
    "plt.plot(np.arange(len(lfp_dHP_data[1, str_idx:end_idx])),lfp_dHP_data[1, str_idx:end_idx], alpha=0.8)\n",
    "plt.plot(np.arange(len(lfp_dHP_data[2, str_idx:end_idx])),lfp_dHP_data[2, str_idx:end_idx], alpha=0.8)\n",
    "\n",
    "# Plot the non-overlapping dHP spwrs\n",
    "for i, central_frame in enumerate(dHP_non_overlapping_centralFrames):\n",
    "    x_axis = range(dHP_non_overlapping_centralFrames[i]-100, dHP_non_overlapping_centralFrames[i]+101)\n",
    "    plt.plot(x_axis,non_overlapping_lfp_dHP_spwr[0, i, :], 'r')\n",
    "    plt.plot(x_axis,non_overlapping_lfp_dHP_spwr[1, i, :], 'r')\n",
    "    plt.plot(x_axis,non_overlapping_lfp_dHP_spwr[2, i, :], 'r')\n",
    "    \n",
    "#\"\"\"\n",
    "# Plot all labelled spwr\n",
    "for i, central_frame in enumerate(sorted_ripple_centralFrames[0, :]):\n",
    "    start_idx = sorted_ripple_centralFrames[0, i]-100\n",
    "    end_idx = sorted_ripple_centralFrames[0, i]+101\n",
    "    x_axis = range(start_idx, end_idx)\n",
    "    plt.plot(x_axis,lfp_dHP_data[0, start_idx:end_idx], 'b', alpha=0.2)\n",
    "    plt.plot(x_axis,lfp_dHP_data[1, start_idx:end_idx], 'b', alpha=0.2)\n",
    "    plt.plot(x_axis,lfp_dHP_data[2, start_idx:end_idx], 'b', alpha=0.2)\n",
    "#\"\"\"\n",
    "\n",
    "#Segment of the data without no spwr labelled inside of it\n",
    "\"\"\"\n",
    "noise_start = 5800000\n",
    "noise_end = 5900000\n",
    "noisy_data = lfp_dHP_data[:, noise_start:noise_end]\n",
    "#plt.plot(range(noise_start,noise_end), lfp_dHP_data[0, noise_start:noise_end], 'k', alpha=0.8)\n",
    "#plt.plot(range(noise_start,noise_end), lfp_dHP_data[1, noise_start:noise_end], 'k', alpha=0.8)\n",
    "#plt.plot(range(noise_start,noise_end), lfp_dHP_data[2, noise_start:noise_end], 'k', alpha=0.8)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"  \n",
    "print(\"Plotting frames without labelled spwr\")\n",
    "plt.plot(non_spwr_frames,lfp_dHP_data[0, non_spwr_frames], 'k', alpha=0.8)\n",
    "plt.plot(non_spwr_frames,lfp_dHP_data[1, non_spwr_frames], 'k', alpha=0.8)\n",
    "plt.plot(non_spwr_frames,lfp_dHP_data[2, non_spwr_frames], 'k', alpha=0.8)\n",
    "\"\"\"\n",
    "\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679555f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data information\n",
    "print(\"Number of total frames: \", len(lfp_dHP_data[0, :]))\n",
    "print(\"Number of non-labelled spwr frames: \", len(non_spwr_frames))\n",
    "print(\"Num total centralFrames spwr frames: \", num_total_spwr*201)\n",
    "print(\"Num total spwr frames with 100ms around centralFrame: \", len(lfp_dHP_data[0, :]) - num_total_spwr*201)\n",
    "print(\"Num total dHP spwr frames with 100ms around centralFrame: \", sum(non_overlapping_dHP_spwr_bool)*201)\n",
    "print(\"Number of non-overlapping dHP spwr: \", num_non_overlapping_dHP_spwr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b8fa22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d9cde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For plotting a single ripple by providing the ripple_id which is a number 0-non_overlapping_lfp_dHP_spwr.shape[1]\n",
    "ripple_id = 150\n",
    "plt.figure()\n",
    "plt.plot(np.arange(len(non_overlapping_lfp_dHP_spwr[0, ripple_id, :])),non_overlapping_lfp_dHP_spwr[0, ripple_id, :])\n",
    "plt.plot(np.arange(len(non_overlapping_lfp_dHP_spwr[1, ripple_id, :])),non_overlapping_lfp_dHP_spwr[1, ripple_id, :])\n",
    "plt.plot(np.arange(len(non_overlapping_lfp_dHP_spwr[2, ripple_id, :])),non_overlapping_lfp_dHP_spwr[2, ripple_id, :])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ab955e",
   "metadata": {},
   "source": [
    "# Should these considered spwrs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff27c60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#35 bad centralFrame?\n",
    "#78, 206 and 294, 310 are not ripples right?\n",
    "maybe_not_ripples_id = [1,3,6,7,8,9,12,13,15,17,34,35,41,44,60,61,67,71,77,78,79,80,94,99,104,178,206,294,300,310,313]\n",
    "\n",
    "#for ripple_id in range(0, non_overlapping_lfp_dHP_spwr.shape[1]):\n",
    "for ripple_id in maybe_not_ripples_id:\n",
    "    print(ripple_id)\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(len(non_overlapping_lfp_dHP_spwr[0, ripple_id, :])),non_overlapping_lfp_dHP_spwr[0, ripple_id, :])\n",
    "    plt.plot(np.arange(len(non_overlapping_lfp_dHP_spwr[1, ripple_id, :])),non_overlapping_lfp_dHP_spwr[1, ripple_id, :])\n",
    "    plt.plot(np.arange(len(non_overlapping_lfp_dHP_spwr[2, ripple_id, :])),non_overlapping_lfp_dHP_spwr[2, ripple_id, :])\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3411d60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For plotting more than just the 200 frames around a ripple centralFrame.\n",
    "#Given id, get centralFrame and then give the number of frames to the left and right of the centralframe to be plotted.\n",
    "\n",
    "ripple_id = 150\n",
    "centralFrame_of_ripple = dHP_non_overlapping_centralFrames[ripple_id]\n",
    "\n",
    "#The ripple before the current ripple\n",
    "#print(sorted_ripple_centralFrames[:, 250:300])\n",
    "#print(centralFrame_of_ripple)\n",
    "#centralFrame_of_ripple = 1177374\n",
    "\n",
    "frame_range = range(centralFrame_of_ripple-200, centralFrame_of_ripple+101)\n",
    "plt.figure()\n",
    "plt.plot(np.arange(len(lfp_dHP_data[0, frame_range])),lfp_dHP_data[0, frame_range])\n",
    "plt.plot(np.arange(len(lfp_dHP_data[1, frame_range])),lfp_dHP_data[1, frame_range])\n",
    "plt.plot(np.arange(len(lfp_dHP_data[2, frame_range])),lfp_dHP_data[2, frame_range])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a21d71c",
   "metadata": {},
   "source": [
    "### IS THIS A SPWR? ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3083a85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unlabelled potential ripple that I found myself.\n",
    "print(sorted_ripple_centralFrames[(5384000 < sorted_ripple_centralFrames) & (sorted_ripple_centralFrames < 5384300)])\n",
    "sorted_ripple_centralFrames[(5100000 < sorted_ripple_centralFrames) & (sorted_ripple_centralFrames < 5384300)]\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "str_idx = 5384000\n",
    "end_idx = 5384300\n",
    "#str_idx = 5384500\n",
    "#end_idx = 5384650\n",
    "plt.plot(np.arange(len(lfp_dHP_data[0, str_idx:end_idx])),lfp_dHP_data[0, str_idx:end_idx])\n",
    "plt.plot(np.arange(len(lfp_dHP_data[1, str_idx:end_idx])),lfp_dHP_data[1, str_idx:end_idx])\n",
    "plt.plot(np.arange(len(lfp_dHP_data[2, str_idx:end_idx])),lfp_dHP_data[2, str_idx:end_idx])\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec2dfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Low drop spwr, good to know not all spwr events drop to around -1000\n",
    "str_idx = 6293668-100\n",
    "end_idx = 6293668+101\n",
    "plt.plot(np.arange(len(lfp_dHP_data[0, str_idx:end_idx])),lfp_dHP_data[0, str_idx:end_idx])\n",
    "plt.plot(np.arange(len(lfp_dHP_data[1, str_idx:end_idx])),lfp_dHP_data[1, str_idx:end_idx])\n",
    "plt.plot(np.arange(len(lfp_dHP_data[2, str_idx:end_idx])),lfp_dHP_data[2, str_idx:end_idx])\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee0390f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e728ec18",
   "metadata": {},
   "source": [
    "# Noisy data\n",
    "### Instructions\n",
    "What I have done here is to select an interval based on the entire dataset where there are no labelled ripples (See plot of all data above). After that I looked at 200 frames at a time and manually wrote down the ranges of frames that were potentially not to be considered noise. I did this for a range of 100000 because I needed 439 * 201 = 88239 noise frames initially to have an equally large noise dataset as spwr dataset. However, due to a bug in my code this was later reduced to 319 * 201 but I could still use the same range. If one has a larger spwr dataset one would have to go through a larger range of non-labelled data and write down the ranges with potentially non-noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18f26d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Don't have it run this\n",
    "\n",
    "noise_start = 5800000\n",
    "noise_end = 5900000\n",
    "\n",
    "#Have done the first 500 (0-499 in python)\n",
    "for i in range(1, 2):\n",
    "    str_idx = noise_start + i*200\n",
    "    end_idx = noise_start + (i+1)*200\n",
    "    print(\"range(\" + str(str_idx) + \",\" + str(end_idx) + \")\")\n",
    "    plt.figure()\n",
    "    noisy_data_ch1 = lfp_dHP_data[0, str_idx:end_idx]\n",
    "    noisy_data_ch2 = lfp_dHP_data[1, str_idx:end_idx]\n",
    "    noisy_data_ch3 = lfp_dHP_data[2, str_idx:end_idx]\n",
    "    plt.plot(noisy_data_ch1, 'b')\n",
    "    plt.plot(noisy_data_ch2, color='C1')\n",
    "    plt.plot(noisy_data_ch3, 'g')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dd342d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I manually stepped through the data from frame 5800000 to 5900000 and picked out events of interest\n",
    "#These were parts of the signal that looked like:\n",
    "    #spwrs that hadn't been labelled\n",
    "    #Sharp drops in all channels that could be an indication of the sharp drop in spwr\n",
    "    #Inverted spwrs with the lowest channel on top and the highest channel at the bottom\n",
    "#After talking to Peter and going through the data again we determined that only some spwr_like events\n",
    "#should be excluded from the dataset as labelling them as noise could be wrong even if the \n",
    "#automatic detection algorithm from buzaki did not classify that part of the signal as a spwr.\n",
    "spwr_like_string = \"\"\"#spwr-like\n",
    "range(5864600,5864800)\n",
    "#spwr-like\n",
    "range(5867400,5867600)\n",
    "#two spwr?\n",
    "range(5869600,5869800)\n",
    "#spwr-like\n",
    "range(5870000,5870200)\n",
    "#spwr_like\n",
    "range(5871400,5871700)\n",
    "#spwr_like\n",
    "range(5896300,5896500)\n",
    "#spwr_like\n",
    "range(5888700,5888900)\n",
    "#spwr-like\n",
    "range(5885900,5886100)\n",
    "#spwr-like\n",
    "range(5882600,5882800)\n",
    "#spwr_like\n",
    "range(5879800,5880000)\n",
    "#spwr_like\n",
    "range(5878600,5878800)\n",
    "#spwr_like\n",
    "range(5877800,5878000)\n",
    "#spwr_like\n",
    "range(5876400,5876600)\n",
    "#spwr_like\n",
    "range(5874700,5874900)\n",
    "#spwr_like\n",
    "range(5874400,5874600)\n",
    "#spwr_like\n",
    "range(5873000,5873200)\n",
    "#spwr-like\n",
    "range(5872200,5872400)\n",
    "#spwr-like\n",
    "range(5802200,5802400)\n",
    "#spwr-like\n",
    "range(5804800,5805000)\n",
    "#spwr-like\n",
    "range(5805800,5806200)\n",
    "#spwr-like\n",
    "range(5807100,5807500)\n",
    "#spwr-like\n",
    "range(5808600,5809000)\n",
    "#spwr-like\n",
    "range(5828400,5828600)\n",
    "#spwr-like\n",
    "range(5839000,5839200)\n",
    "#spwr-like and invert\n",
    "range(5840800,5841800)\n",
    "#spwr-like\n",
    "range(5844350,5844550)\n",
    "#spwr-like\n",
    "range(5847800,5848000)\n",
    "#spwr_like\n",
    "range(5851000,5851600)\n",
    "#Inverted spwr?\n",
    "range(5851800,5852000)\n",
    "#spwr-like\n",
    "range(5852400,5852600)\n",
    "#Two spwrs?\n",
    "range(5853400,5853800)\"\"\"\n",
    "\n",
    "#Convert string of ranges to list of ranges\n",
    "# Extract spwr like ranges\n",
    "spwr_like = []\n",
    "a_splitted = spwr_like_string.split('\\n')\n",
    "for i, part in enumerate(a_splitted):\n",
    "    if(i % 2):\n",
    "        spwr_like_frames = 0\n",
    "        test = 'spwr_like_frames = '+ part\n",
    "        exec(test)\n",
    "        spwr_like.append(spwr_like_frames)\n",
    "        \n",
    "#Sort the list according to the first frame in each range\n",
    "spwr_like = sorted(spwr_like, key=lambda r: r.start)\n",
    "\n",
    "sharp_drops = [range(5814200, 5814400), range(5814900, 5815100), range(5818200, 5818400), range(5850400, 5850700)\\\n",
    ", range(5844200, 5844400), range(5837200, 5837400), range(5836600, 5836800), range(5831600, 5831800)\\\n",
    ",range(5810750, 5811100), range(5801700, 5801900), range(5872600, 5872800), range(5860400, 5860600)\\\n",
    ",range(5867600,5867800)]\n",
    "\n",
    "inverted_spwr = [range(5881400,5881600), range(5810700, 5810900), range(5823200, 5823400), range(5880200,5880400) \\\n",
    ", range(5880800,5881200), range(5882200,5882400), range(5885000,5885200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fd967f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63de924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "450f78c2",
   "metadata": {},
   "source": [
    "# Checking sharp drop, inverted and spwr-like to see if they can be noise\n",
    "For each of the identified potentially non-noise ranges of each time I then plotted the data again to go through them with Peter and determine if it should be considered noise or spwr. The conclusion was that the inverted spwrs and sharp drops could be considered noise but some of the spwr_like signals might be unlabelled spwrs. The ranges of those spwr_like signals were therefore saved and then excluded when creating the noise dataset by only gathering data outside of those ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d656d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, frames in enumerate(inverted_spwr):\n",
    "    print(i)\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(len(lfp_dHP_data[0, frames])),lfp_dHP_data[0, frames], 'b')\n",
    "    plt.plot(np.arange(len(lfp_dHP_data[1, frames])),lfp_dHP_data[1, frames], 'C1')\n",
    "    plt.plot(np.arange(len(lfp_dHP_data[2, frames])),lfp_dHP_data[2, frames], 'g')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\"\"\"\n",
    "#4\n",
    "frames = range(5881000,5881200)\n",
    "plt.figure()\n",
    "plt.plot(np.arange(len(lfp_dHP_data[0, frames])),lfp_dHP_data[0, frames], 'b')\n",
    "plt.plot(np.arange(len(lfp_dHP_data[1, frames])),lfp_dHP_data[1, frames], 'C1')\n",
    "plt.plot(np.arange(len(lfp_dHP_data[2, frames])),lfp_dHP_data[2, frames], 'g')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\"\"\"\n",
    "#Probably fine\n",
    "inverted_spwr_noisy = [0,1,2,3,4,5,6]\n",
    "#Check with Peter\n",
    "inverted_spwr_no_noisy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83adaf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c161345",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, frames in enumerate(sharp_drops):\n",
    "    print(i)\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(len(lfp_dHP_data[0, frames])),lfp_dHP_data[0, frames], 'b')\n",
    "    plt.plot(np.arange(len(lfp_dHP_data[1, frames])),lfp_dHP_data[1, frames], 'C1')\n",
    "    plt.plot(np.arange(len(lfp_dHP_data[2, frames])),lfp_dHP_data[2, frames], 'g')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "#Probably fine\n",
    "sharp_drops_noisy = [0,1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "#Check with Peter\n",
    "sharp_drops_no_noisy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec69b94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed12aa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, frames in enumerate(spwr_like):\n",
    "    print(i)\n",
    "    print(frames)\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(len(lfp_dHP_data[0, frames])),lfp_dHP_data[0, frames], 'b')\n",
    "    plt.plot(np.arange(len(lfp_dHP_data[1, frames])),lfp_dHP_data[1, frames], 'C1')\n",
    "    plt.plot(np.arange(len(lfp_dHP_data[2, frames])),lfp_dHP_data[2, frames], 'g')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "#Probably fine\n",
    "spwr_like_probably_noise = [4,5,6,7,8,9,10,11,12,15,16,18,22,27,28,30]\n",
    "#Check with Peter\n",
    "#25 too large interval\n",
    "#28 too large interval\n",
    "spwr_like_not_noise = [0,1,2,3,13,14,17,19,20,21,23,24,25,26,29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e2a438",
   "metadata": {},
   "outputs": [],
   "source": [
    "#25\n",
    "frames = range(5840800,5841600)\n",
    "plt.figure()\n",
    "plt.plot(np.arange(len(lfp_dHP_data[0, frames])),lfp_dHP_data[0, frames], 'b')\n",
    "plt.plot(np.arange(len(lfp_dHP_data[1, frames])),lfp_dHP_data[1, frames], 'C1')\n",
    "plt.plot(np.arange(len(lfp_dHP_data[2, frames])),lfp_dHP_data[2, frames], 'g')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4096756f",
   "metadata": {},
   "source": [
    "## Create noise dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f3d363",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Noise dataset is created using data from frame 5800000 to 5900000\n",
    "noise_start = 5800000\n",
    "noise_end = 5900000\n",
    "\n",
    "#num_channel, num_dHP in dataset, signal length\n",
    "noisy_lfp_dHP = np.zeros((num_channels, num_non_overlapping_dHP_spwr, spwr_size)) \n",
    "\n",
    "#Curr noise_sample\n",
    "i = 0\n",
    "\n",
    "start_frame = noise_start\n",
    "end_frame = start_frame + spwr_size\n",
    "\n",
    "#Keep track of which spwr_like data we are currently at\n",
    "curr_spwr_like_idx = 0\n",
    "\n",
    "curr_spwr_like_start = spwr_like[spwr_like_not_noise[curr_spwr_like_idx]][0]\n",
    "curr_spwr_like_end = spwr_like[spwr_like_not_noise[curr_spwr_like_idx]][-1]\n",
    "\n",
    "#While we still need more data samples for the noise dataset\n",
    "while i < num_non_overlapping_dHP_spwr:\n",
    "    \n",
    "    #If noise_data sample has passed the current spwr_like data start\n",
    "    if(end_frame >= curr_spwr_like_start):\n",
    "        \n",
    "        #Set current noise data to the frames after the spwr_like data\n",
    "        start_frame = curr_spwr_like_end + 1\n",
    "        end_frame = start_frame + (spwr_size)\n",
    "        \n",
    "        #and set spwr_like data to the next spwr_like data.\n",
    "        curr_spwr_like_idx += 1\n",
    "        \n",
    "        #if we still have spwr_like data left update the start and end of it, else set the pointer to the end of the noise\n",
    "        #this is done so that when there is no spwr_like data left the above if statement will only trigger when\n",
    "        #we run out of data, i.e. go past the noise_end limit.\n",
    "        if(curr_spwr_like_idx < len(spwr_like_not_noise)):\n",
    "            curr_spwr_like_start = spwr_like[spwr_like_not_noise[curr_spwr_like_idx]][0]\n",
    "            curr_spwr_like_end = spwr_like[spwr_like_not_noise[curr_spwr_like_idx]][-1]\n",
    "        \n",
    "        else:\n",
    "            curr_spwr_like_start = noise_end \n",
    "    \n",
    "    #If we are not at risk of sampling spwr_like data we simply add a datapoint to the noise dataset.\n",
    "    else:\n",
    "        start_frame = end_frame\n",
    "        end_frame += 201\n",
    "        noisy_lfp_dHP[0, i, :] = lfp_dHP_data[0, start_frame:end_frame]\n",
    "        noisy_lfp_dHP[1, i, :] = lfp_dHP_data[1, start_frame:end_frame]\n",
    "        noisy_lfp_dHP[2, i, :] = lfp_dHP_data[2, start_frame:end_frame]\n",
    "        i += 1\n",
    "\n",
    "    #This only triggers if there is not enough data in the set range\n",
    "    #To solve this one must extend the range, go through the data manually and pick out events that could be unlabelled spwrs\n",
    "    if(end_frame > noise_end):\n",
    "        print(\"NEED MORE DATA\")\n",
    "        break\n",
    "\n",
    "#Should be less than noise_end\n",
    "print(\"Current end frame: \", end_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16ed320",
   "metadata": {},
   "source": [
    "# Fine tune the noise dataset\n",
    "After I have created a noise dataset I went through all of the noise datapoints and found potential spwrs that I missed during the first investigation of the data from 5800000 to 5900000. I saved their indicies in the maybe_non_noise_indicies aray and replaced them with noise collected after the last collected noise datapoint. But this was also done manually as I found x amount of sequential 201 datapoints. This was done by adding a number to the frames after the last recorded noise dataframe and then looking through the data until enough sequential non-noise data was found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adc1982",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot each of the noise sampled datapoints\n",
    "for i in range(noisy_lfp_dHP.shape[1]):\n",
    "    print(i)\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(noisy_lfp_dHP.shape[2]),noisy_lfp_dHP[0, i, :], 'b')\n",
    "    plt.plot(np.arange(noisy_lfp_dHP.shape[2]),noisy_lfp_dHP[1, i, :], 'C1')\n",
    "    plt.plot(np.arange(noisy_lfp_dHP.shape[2]),noisy_lfp_dHP[2, i, :], 'g')\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0847b3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALL OF THESE ARE INTERESTING TO EVALUATE THE ALGORITHM ON. DOES IT THINK THESE ARE NOISE OR SPWR?\n",
    "#263 ripple?\n",
    "#Possibly data that should not be considered noise that is currently in the noise dataset\n",
    "#!!!NOTE!!! These indicies will increase if based on the number of noise samples required\n",
    "#TODO Maybe fix this so that it is more automated.\n",
    "maybe_non_noise_indicies = np.array([33, 184, 194, 195, 210, 227, 250, 263, 321, 332])\n",
    "\n",
    "#Only remove the indicies that are in the current dataset\n",
    "maybe_non_noise_indicies = maybe_non_noise_indicies[maybe_non_noise_indicies < noisy_lfp_dHP.shape[1]-1] #-1 to exclude ind if it is the last\n",
    "print(\"Current indicies in noise data that should not be considered noise: \", maybe_non_noise_indicies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503b857b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f32731",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code is to extract additional noise data to replace possibly non-noise in the noise dataset\n",
    "\n",
    "print(\"Current start frame: \", start_frame)\n",
    "print(\"Current end_frame: \", end_frame)\n",
    "\n",
    "#The +4600 is something I found so that the next noisy_lfp_dHP.shape[1] number \n",
    "#of 201 frame bundles do not contain a spwr_like signal\n",
    "#TODO: x and y are bad names but I need something other than start and end to not overwrite them.\n",
    "x_frame = start_frame+4600\n",
    "y_frame = end_frame+4600\n",
    "\n",
    "frame_range = range(x_frame,y_frame)\n",
    "\n",
    "#Check that the next number: noisy_lfp_dHP.shape[1] data samples are noise\n",
    "for i in range(0, maybe_non_noise_indicies.shape[0]):\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(len(lfp_dHP_data[0, frame_range])),lfp_dHP_data[0, frame_range], 'b')\n",
    "    plt.plot(np.arange(len(lfp_dHP_data[1, frame_range])),lfp_dHP_data[1, frame_range], 'C1')\n",
    "    plt.plot(np.arange(len(lfp_dHP_data[2, frame_range])),lfp_dHP_data[2, frame_range], 'g')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    x_frame = y_frame\n",
    "    y_frame = x_frame + 201\n",
    "    frame_range = range(x_frame,y_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a790c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save possibly spwr data in the noise dataset for later analysis\n",
    "#and replace it with noise from the next timesteps after the last one.\n",
    "\n",
    "x_frame = start_frame+4600\n",
    "y_frame = end_frame+4600\n",
    "\n",
    "maybe_spwr_data = np.zeros((3, len(maybe_non_noise_indicies), spwr_size))\n",
    "for i, idx in enumerate(maybe_non_noise_indicies):\n",
    "    #Save possibly spwr data for testing\n",
    "    maybe_spwr_data[0, i, :] = noisy_lfp_dHP[0, idx, :]\n",
    "    maybe_spwr_data[1, i, :] = noisy_lfp_dHP[1, idx, :]\n",
    "    maybe_spwr_data[2, i, :] = noisy_lfp_dHP[2, idx, :]\n",
    "    #Replace possibly spwr data with noisy data\n",
    "    noisy_lfp_dHP[0, idx, :] = lfp_dHP_data[0, x_frame:y_frame]\n",
    "    noisy_lfp_dHP[1, idx, :] = lfp_dHP_data[1, x_frame:y_frame]\n",
    "    noisy_lfp_dHP[2, idx, :] = lfp_dHP_data[2, x_frame:y_frame]\n",
    "    \n",
    "    x_frame = y_frame\n",
    "    y_frame += spwr_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73e7cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "maybe_non_noise_indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb251014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2353f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93336d24",
   "metadata": {},
   "source": [
    "# Prepare the data for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ef7494",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Normalize, Standarize and split the data into a train and a test set###\n",
    "\n",
    "#Normalize the data together\n",
    "data = np.zeros((num_channels, num_non_overlapping_dHP_spwr*2, spwr_size))\n",
    "data[0] = np.concatenate((non_overlapping_lfp_dHP_spwr[0], noisy_lfp_dHP[0]))\n",
    "data[1] = np.concatenate((non_overlapping_lfp_dHP_spwr[1], noisy_lfp_dHP[1]))\n",
    "data[2] = np.concatenate((non_overlapping_lfp_dHP_spwr[2], noisy_lfp_dHP[2]))\n",
    "\n",
    "data_norm = np.zeros(data.shape)\n",
    "\n",
    "#Z-normalization\n",
    "channel_means = np.mean(data, axis=(1,2))\n",
    "channel_stds = np.std(data, axis=(1,2))\n",
    "data_norm[0] = (data[0] - channel_means[0]) / channel_stds[0]\n",
    "data_norm[1] = (data[1] - channel_means[1]) / channel_stds[1]\n",
    "data_norm[2] = (data[2] - channel_means[2]) / channel_stds[2]\n",
    "print(\"Channel means: \", channel_means)\n",
    "print(\"Channel stds: \", channel_stds)\n",
    "\n",
    "#Min-max normalization\n",
    "channel_mins = np.amin(data, axis=(1,2))\n",
    "channel_maxs = np.amax(data, axis=(1,2))\n",
    "print(\"Channel mins: \", channel_mins)\n",
    "print(\"Channel maxs: \", channel_maxs)\n",
    "\n",
    "data_norm[0] = (data[0] - channel_mins[0]) / (channel_maxs[0]-channel_mins[0])\n",
    "data_norm[1] = (data[1] - channel_mins[1]) / (channel_maxs[1]-channel_mins[1])\n",
    "data_norm[2] = (data[2] - channel_mins[2]) / (channel_maxs[2]-channel_mins[2])\n",
    "\n",
    "#Separate back to spwr and noise to ensure equal number of spwr and noise in train/test\n",
    "spwr_data_norm = data_norm[:, :num_non_overlapping_dHP_spwr, :]\n",
    "noise_data_norm = data_norm[:, num_non_overlapping_dHP_spwr:, :]\n",
    "\n",
    "#Create labels\n",
    "spwr_labels = np.ones((num_non_overlapping_dHP_spwr), dtype=int)\n",
    "noise_labels = np.zeros((num_non_overlapping_dHP_spwr),dtype=int)\n",
    "labels = np.concatenate((spwr_labels, noise_labels))\n",
    "\n",
    "#Shuffle the spwr and noise data randomly separately\n",
    "ind = np.random.permutation(spwr_data_norm.shape[1])\n",
    "train_test_split = 0.8\n",
    "half_train_size = int(len(ind)*train_test_split)\n",
    "half_test_size = num_non_overlapping_dHP_spwr-half_train_size\n",
    "train_size = half_train_size*2\n",
    "test_size = half_test_size*2\n",
    "\n",
    "print(\"Num training examples: \", train_size)\n",
    "print(\"Num test examples: \", test_size)\n",
    "\n",
    "spwr_data_norm_train = spwr_data_norm[:, ind[:half_train_size], :]\n",
    "noise_data_norm_train = noise_data_norm[:, ind[:half_train_size], :]\n",
    "spwr_data_norm_test = spwr_data_norm[:, ind[half_train_size:], :]\n",
    "noise_data_norm_test = noise_data_norm[:, ind[half_train_size:], :]\n",
    "\n",
    "x_train = np.zeros((num_channels, train_size, spwr_size))\n",
    "x_train[:, :half_train_size, :] = spwr_data_norm_train\n",
    "x_train[:, half_train_size:, :] = noise_data_norm_train\n",
    "y_train = np.concatenate((spwr_labels[ind[:half_train_size]], noise_labels[ind[:half_train_size]]))\n",
    "\n",
    "x_test = np.zeros((num_channels, test_size, spwr_size))\n",
    "x_test[:, :half_test_size, :] = spwr_data_norm_test\n",
    "x_test[:, half_test_size:, :] = noise_data_norm_test\n",
    "y_test = np.concatenate((spwr_labels[ind[half_train_size:]], noise_labels[ind[half_train_size:]]))\n",
    "\n",
    "train_perm_ind = np.random.permutation(train_size)\n",
    "test_perm_ind = np.random.permutation(test_size)\n",
    "\n",
    "#Shuffle the data again but for spwr and noise together in train and test\n",
    "x_train = x_train[:, train_perm_ind, :]\n",
    "y_train = y_train[train_perm_ind]\n",
    "x_test = x_test[:, test_perm_ind, :]\n",
    "y_test = y_test[test_perm_ind]\n",
    "\n",
    "#For Keras model input as it expect (datapoint_ind, data, feature number)\n",
    "x_train = np.transpose(x_train, axes=(1,2,0))\n",
    "x_test = np.transpose(x_test, axes=(1,2,0))\n",
    "\n",
    "num_classes = len(np.unique(y_train))\n",
    "print(\"Number of classes: \", num_classes)\n",
    "print(\"x train shape: \", x_train.shape) \n",
    "print(\"y train shape: \", y_train.shape) \n",
    "print(\"x test shape: \", x_test.shape)\n",
    "print(\"y test shape: \", y_test.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d753d61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd53122a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make model\n",
    "\n",
    "###Change these to not have an old model get overwritten###\n",
    "main_name = \"test\"\n",
    "model_name = main_name + \"_model.h5\"\n",
    "fig_name = main_name + \"_model_epoch_accuracy.pdf\"\n",
    "\n",
    "def make_model(input_shape):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "\n",
    "    conv1 = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(input_layer)\n",
    "    conv1 = keras.layers.BatchNormalization()(conv1)\n",
    "    conv1 = keras.layers.ReLU()(conv1)\n",
    "\n",
    "    conv2 = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(conv1)\n",
    "    conv2 = keras.layers.BatchNormalization()(conv2)\n",
    "    conv2 = keras.layers.ReLU()(conv2)\n",
    "\n",
    "    conv3 = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(conv2)\n",
    "    conv3 = keras.layers.BatchNormalization()(conv3)\n",
    "    conv3 = keras.layers.ReLU()(conv3)\n",
    "\n",
    "    gap = keras.layers.GlobalAveragePooling1D()(conv3)\n",
    "\n",
    "    output_layer = keras.layers.Dense(num_classes, activation=\"softmax\")(gap)\n",
    "\n",
    "    return keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "\n",
    "model = make_model(input_shape=x_train.shape[1:])\n",
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9942ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train model\n",
    "epochs = 500\n",
    "batch_size = 32\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        model_name, save_best_only=True, monitor=\"val_loss\"\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\", factor=0.5, patience=20, min_lr=0.0001\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, verbose=1),\n",
    "]\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"sparse_categorical_accuracy\"],\n",
    ")\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_split=0.2,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cd1055",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test model\n",
    "model = keras.models.load_model(model_name)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(\"Test accuracy\", test_acc)\n",
    "print(\"Test loss\", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96830cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and test loss\n",
    "metric = \"sparse_categorical_accuracy\"\n",
    "plt.figure()\n",
    "plt.plot(history.history[metric])\n",
    "plt.plot(history.history[\"val_\" + metric])\n",
    "plt.title(\"model \" + metric)\n",
    "plt.ylabel(metric, fontsize=\"large\")\n",
    "plt.xlabel(\"epoch\", fontsize=\"large\")\n",
    "plt.legend([\"train\", \"val\"], loc=\"best\")\n",
    "plt.savefig(fig_name)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5040ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lfp_data(lfp_data):\n",
    "    \"\"\"\n",
    "    This function plots the lfp_data, 200 frames at a time\n",
    "    \n",
    "    Parameters:\n",
    "        - lfp_data has shape (num_channels, num_samples, spwr_size)\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    for i in range(lfp_data.shape[1]):\n",
    "        print(i)\n",
    "        plt.figure()\n",
    "        plt.plot(np.arange(lfp_data.shape[2]), lfp_data[0, i, :], 'b')\n",
    "        plt.plot(np.arange(lfp_data.shape[2]), lfp_data[1, i, :], 'C1')\n",
    "        plt.plot(np.arange(lfp_data.shape[2]), lfp_data[2, i, :], 'g')\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cd6b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the lfp data of the frames that were removed from the noise dataset because of possibly being spwrs.  \n",
    "plot_lfp_data(maybe_spwr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441bf894",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All of the events that I removed from the noise dataset because I thought they looked too much like ripples\n",
    "#are classified as ripples by the model.\n",
    "\n",
    "def preprocess_lfp_data_min_max_norm(lfp_data, mins, maxs):\n",
    "    test_data = np.zeros(lfp_data.shape)\n",
    "    test_data[0] = (lfp_data[0] - mins[0]) / (maxs[0] - mins[0])\n",
    "    test_data[1] = (lfp_data[1] - mins[1]) / (maxs[1] - mins[1])\n",
    "    test_data[2] = (lfp_data[2] - mins[2]) / (maxs[2] - mins[2])\n",
    "    return np.transpose(test_data, axes=(1,2,0))\n",
    "\n",
    "def preprocess_lfp_data_z_norm(lfp_data, means, stds):\n",
    "    test_data = np.zeros(lfp_data.shape)\n",
    "    test_data[0] = (lfp_data[0] - means[0]) / stds[0]\n",
    "    test_data[1] = (lfp_data[1] - means[1]) / stds[1]\n",
    "    test_data[2] = (lfp_data[2] - means[2]) / stds[2]\n",
    "    return np.transpose(test_data, axes=(1,2,0))\n",
    "\n",
    "#y_hat = model.predict(preprocess_lfp_data_z_norm(maybe_spwr_data, channel_mins, channel_maxs))\n",
    "y_hat = model.predict(preprocess_lfp_data_min_max_norm(maybe_spwr_data, channel_mins, channel_maxs))\n",
    "print(y_hat)\n",
    "print(np.argmax(y_hat, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126ee548",
   "metadata": {},
   "outputs": [],
   "source": [
    "#100% accuracy on the test data\n",
    "y_hat = model.predict(x_test)\n",
    "print(np.argmax(y_hat, axis=1))\n",
    "print(y_test)\n",
    "print(np.argmax(y_hat, axis=1) - y_test)\n",
    "print(\"Number of errors on test data: \", np.sum(np.abs(np.argmax(y_hat, axis=1) - y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58075db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test dataset to evaluate the model performance on new frames it has never seen before\n",
    "\n",
    "\"\"\"\n",
    "Good examples:\n",
    "num_samples = 10\n",
    "start_frame = 3020000\n",
    "#4,5 and 7\n",
    "\"\"\"\n",
    "\n",
    "num_samples = 10\n",
    "start_frame = 3020000\n",
    "end_frame = start_frame + spwr_size\n",
    "frame_range = range(start_frame, end_frame)\n",
    "\n",
    "more_test_data = np.zeros((num_channels, num_samples, spwr_size)) \n",
    "for sample in range(num_samples):\n",
    "    more_test_data[:, sample, :] = lfp_dHP_data[:, frame_range]\n",
    "    start_frame = end_frame\n",
    "    end_frame += spwr_size\n",
    "    frame_range = range(start_frame, end_frame)\n",
    "\n",
    "#y_hat = model.predict(preprocess_lfp_data_z_norm(more_test_data, channel_means, channel_stds))\n",
    "y_hat = model.predict(preprocess_lfp_data_min_max_norm(more_test_data, channel_mins, channel_maxs))\n",
    "#print(y_hat)\n",
    "print(np.argmax(y_hat, axis=1))\n",
    "        \n",
    "plot_lfp_data(more_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aadabb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For online classification investigation\n",
    "\n",
    "#This is a ripple in the dataset\n",
    "ripple_id = 150\n",
    "centralFrame_of_ripple = dHP_non_overlapping_centralFrames[ripple_id]\n",
    "\n",
    "offset = 150\n",
    "\n",
    "curr_start_f = centralFrame_of_ripple - offset - 100\n",
    "ripple_end_f = centralFrame_of_ripple + 101 + offset\n",
    "\n",
    "time_lfp_data = np.zeros((num_channels, ripple_end_f-curr_start_f, spwr_size))\n",
    "ind_f = 0\n",
    "for curr_f in range(curr_start_f, ripple_end_f, 1):\n",
    "    f_range = range(curr_f, curr_f+spwr_size)\n",
    "    time_lfp_data[:, ind_f, :] = lfp_dHP_data[:, f_range]\n",
    "    ind_f += 1\n",
    "\n",
    "y_hat = model.predict(preprocess_lfp_data_min_max_norm(time_lfp_data, channel_mins, channel_maxs))\n",
    "preds = np.argmax(y_hat, axis=1)\n",
    "\n",
    "#Print predictions\n",
    "#print(np.argmax(y_hat, axis=1)) #54-233 model predicts 1\n",
    "\n",
    "start_frames = np.arange(curr_start_f, ripple_end_f, 1)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "                         \n",
    "def animate(i):\n",
    "    ax.clear()\n",
    "    ax.set_xlim(start_frames[i], start_frames[i]+spwr_size)\n",
    "    plot_title = \"Prediction is \" + str(preds[i])\n",
    "    if(preds[i]): \n",
    "        ax.set_title(plot_title, fontsize = 20, color = 'green')\n",
    "        ax.spines['bottom'].set_color('green')\n",
    "        ax.spines['top'].set_color('green')\n",
    "        ax.spines['left'].set_color('green')\n",
    "        ax.spines['right'].set_color('green')\n",
    "    else:\n",
    "        ax.set_title(plot_title, fontsize = 20, color = 'red')\n",
    "        ax.spines['bottom'].set_color('red')\n",
    "        ax.spines['top'].set_color('red')\n",
    "        ax.spines['left'].set_color('red')\n",
    "        ax.spines['right'].set_color('red')\n",
    "        \n",
    "    line1, = ax.plot(np.arange(start_frames[i], start_frames[i]+spwr_size), time_lfp_data[0, i, :], color = 'blue', lw=1)\n",
    "    line2, = ax.plot(np.arange(start_frames[i], start_frames[i]+spwr_size),time_lfp_data[1, i, :], color = 'orange', lw=1)\n",
    "    line3, = ax.plot(np.arange(start_frames[i], start_frames[i]+spwr_size),time_lfp_data[2, i, :], color = 'green', lw=1)\n",
    "    return line1, line2, line3,\n",
    "\n",
    "time_lfp_data.shape[1] - spwr_size\n",
    "ani = FuncAnimation(fig, animate, interval=40, blit=True, repeat=True, frames=ripple_end_f-curr_start_f-200)  \n",
    "ani.save(\"anim.gif\", dpi=300, writer=PillowWriter(fps=25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8ae15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(10, 5))\n",
    "\n",
    "ax1.plot(np.arange(spwr_size),time_lfp_data[0, 53, :], 'b')\n",
    "ax1.plot(np.arange(spwr_size),time_lfp_data[1, 53, :], 'C1')\n",
    "ax1.plot(np.arange(spwr_size),time_lfp_data[2, 53, :], 'g')\n",
    "ax1.set_title(\"TIME 53: PREDICTION IS 0\")\n",
    "ax2.plot(np.arange(spwr_size),time_lfp_data[0, 54, :], 'b')\n",
    "ax2.plot(np.arange(spwr_size),time_lfp_data[1, 54, :], 'C1')\n",
    "ax2.plot(np.arange(spwr_size),time_lfp_data[2, 54, :], 'g')\n",
    "ax2.set_title(\"TIME 54: PREDICTION IS 1\")\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(10, 5))\n",
    "\n",
    "ax1.plot(np.arange(spwr_size),time_lfp_data[0, 233, :], 'b')\n",
    "ax1.plot(np.arange(spwr_size),time_lfp_data[1, 233, :], 'C1')\n",
    "ax1.plot(np.arange(spwr_size),time_lfp_data[2, 233, :], 'g')\n",
    "ax1.set_title(\"TIME 233: PREDICTION IS 1\")\n",
    "ax2.plot(np.arange(spwr_size),time_lfp_data[0, 234, :], 'b')\n",
    "ax2.plot(np.arange(spwr_size),time_lfp_data[1, 234, :], 'C1')\n",
    "ax2.plot(np.arange(spwr_size),time_lfp_data[2, 234, :], 'g')\n",
    "ax2.set_title(\"TIME 234: PREDICTION IS 0\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8777b2fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20756510",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e61d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Noisy dataset samples \n",
    "\n",
    "num_samples = 100\n",
    "\n",
    "more_test_data = np.zeros((num_channels, num_samples, spwr_size)) \n",
    "for channel in range(num_channels):\n",
    "    for sample in range(num_samples):\n",
    "        more_test_data[channel, sample, :] = noisy_lfp_dHP[channel, sample, :]\n",
    "\n",
    "#y_hat = model.predict(preprocess_lfp_data_z_norm(more_test_data, channel_means, channel_stds))\n",
    "y_hat = model.predict(preprocess_lfp_data_min_max_norm(more_test_data, channel_mins, channel_maxs))\n",
    "#print(y_hat)\n",
    "print(np.argmax(y_hat, axis=1))\n",
    "        \n",
    "plot_lfp_data(more_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52c0481",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train dataset\n",
    "\n",
    "ind = 100\n",
    "x_train\n",
    "y_hat = model.predict(x_train)\n",
    "#y_hat = model.predict(get_test_data(preprocess_lfp_data[:, ind:ind+10, :], means, stds))\n",
    "print(y_train)\n",
    "print(np.abs(y_train - np.argmax(y_hat, axis=1)))\n",
    "plot_lfp_data(non_overlapping_lfp_dHP_spwr[:, ind:ind+10, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a753f29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdaf78a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4f9965",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c331a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS CODE GAVE ME 100 Accuracy on the test dataset even though it does not work as I intended because it doesn't remove \n",
    "#a spwr if it overlaps with the previous spwr that has been removed. I.e. if the consecutive spwrs overlaps the third is kept \n",
    "#as long as it does not overlap with the 4th in line spwr. This code does also not include the last spwr even if\n",
    "#it does not overlap with any spwr.\n",
    "\n",
    "#I want to check if 100ms around each ripple centre is free of other ripples, if not it is removed from spwr dataset.\n",
    "#This is done to have isolated spwrs in the training/test set and to avoid the same data in different samples.\n",
    "#Hopefully this allows the model to better learn what a spwr is.\n",
    "timesteps = 100\n",
    "\n",
    "#Copy of all spwr centralFrames. Overlapping spwr frames are removed.\n",
    "copy_centralFrames = np.copy(sorted_ripple_centralFrames)\n",
    "copy_centralFrames = copy_centralFrames.flatten() #Flatten => (num_spwr, )\n",
    " \n",
    "#Current index in array with removed overlapping spwrs\n",
    "idx = 0\n",
    "\n",
    "#Index of current and next spwr of all spwr events\n",
    "curr_spwr = 0\n",
    "next_spwr = 1\n",
    "\n",
    "#spwr events to be removed because of overlapping iHP and dHP as iHP spwr is still captured by dHP channels\n",
    "non_overlapping_spwr = []\n",
    "\n",
    "num_dHP_removed = 0\n",
    "num_iHP_removed = 0\n",
    "\n",
    "#While there are at least 2 spwr events left. If only one left I cannot compare it to anything\n",
    "#TODO do I leave the last spwr out of the dataset even if it does not overlap?\n",
    "num_spwr_left = copy_centralFrames.shape[0] - 1 \n",
    "while idx < num_spwr_left:\n",
    "\n",
    "    curr_ripple_start = copy_centralFrames[idx] - timesteps\n",
    "    curr_ripple_end = copy_centralFrames[idx] + timesteps\n",
    "    next_ripple_start = copy_centralFrames[idx+1] - timesteps\n",
    "    \n",
    "    #If next overlaps with current ripple \n",
    "    if(curr_ripple_start < next_ripple_start < curr_ripple_end):\n",
    "        #Discard both overlapping spwr events one after another\n",
    "        copy_centralFrames = np.delete(copy_centralFrames, idx) #This discard curr\n",
    "        copy_centralFrames = np.delete(copy_centralFrames, idx) #This discards next which is now at curr pos\n",
    "\n",
    "        if(dHP_spwr_bool[curr_spwr]):\n",
    "            num_dHP_removed += 1\n",
    "        \n",
    "        else:\n",
    "            num_iHP_removed += 1\n",
    "        \n",
    "        if(dHP_spwr_bool[curr_spwr+1]):\n",
    "            num_dHP_removed += 1\n",
    "        else:\n",
    "            num_iHP_removed += 1\n",
    "              \n",
    "        num_spwr_left += -2  \n",
    "        curr_spwr += 2\n",
    "        next_spwr += 2\n",
    "    \n",
    "    #No overlap => save current spwr as non-overlapping and go to next spwr\n",
    "    else:\n",
    "        non_overlapping_spwr.append(curr_spwr)\n",
    "        curr_spwr = next_spwr\n",
    "        idx+= 1\n",
    "        next_spwr += 1 \n",
    "    \n",
    "#Check to see if the last ripple is not overlapping\n",
    "print(\"num spwr left: \", num_spwr_left)\n",
    "print(\"idx: \", idx)\n",
    "\n",
    "print(\"Total number of spwr: \", num_total_spwr)\n",
    "print(\"Total number of dHP spwr\", num_dHP_spwr)\n",
    "print(\"Total number of removed overlapping spwr events: \", len(non_overlapping_spwr)) \n",
    "print(\"Number of dHP spwr removed: \", num_dHP_removed)\n",
    "print(\"Number of iHP spwr removed: \", num_iHP_removed)\n",
    "print(\"Portion of total lost spwr events: \", len(non_overlapping_spwr)/num_total_spwr)\n",
    "print(\"Portion of total lost dHP spwr events: \", num_dHP_removed/num_dHP_spwr)\n",
    "\n",
    "#True if spwr event is not removed\n",
    "#False is spwr event is removed\n",
    "kept_spwr_bool = np.full((num_total_spwr), False) # Creates boolean array with all False values\n",
    "for i in non_overlapping_spwr:\n",
    "    kept_spwr_bool[i] = True\n",
    "    \n",
    "#Only non-removed dHP spwr events are kept\n",
    "non_overlapping_dHP_spwr_bool = np.logical_and(kept_spwr_bool, dHP_spwr_bool)\n",
    "print(\"Num non-overlapping dHP spwrs: \", np.sum(non_overlapping_dHP_spwr_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114d785d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "print(dHP_spwr_bool[:12])\n",
    "print(kept_spwr_bool[:12])\n",
    "print(non_overlapping_dHP_spwr_bool[:12])\n",
    "print(sorted_ripple_centralFrames[0, :12])\n",
    "\"\"\"\n",
    "\n",
    "#Check to see that only pairs of spwr events have been removed. \n",
    "#If the difference between two non-overlapping spwr events -1 modulus 2 is not 0 it means the code \n",
    "#above is wrong. Only pairs of spwr events can be removed\n",
    "\n",
    "for i in range(len(non_overlapping_spwr)-1):\n",
    "    if(np.abs(non_overlapping_spwr[i]-non_overlapping_spwr[i+1])>1):\n",
    "        if(non_overlapping_spwr[i+1]-non_overlapping_spwr[i] -1 )% 2:\n",
    "            print(\"BAD\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07da6076",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
